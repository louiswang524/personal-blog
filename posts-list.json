[
  {
    "filename": "understanding-gpt-models.json",
    "title": "Understanding GPT Models - A Deep Dive into Architecture and Components",
    "date": "2025-08-27",
    "category": "Technology",
    "excerpt": "A comprehensive technical guide to GPT model architecture covering tokenization, positional embeddings, attention mechanisms, MLPs, layer normalization, residual connections, and loss functions.",
    "tags": [
      "Machine Learning",
      "Deep Learning",
      "NLP",
      "GPT",
      "Transformers",
      "AI"
    ]
  },
  {
    "filename": "understanding-vllm-architecture.json",
    "title": "Understanding vLLM Architecture - From PagedAttention to Production-Scale LLM Serving",
    "date": "2025-01-07",
    "category": "Technology",
    "excerpt": "A comprehensive technical deep dive into vLLM's architecture, exploring PagedAttention innovation, memory optimizations, and how to contribute to this high-performance LLM inference engine.",
    "tags": [
      "Machine Learning",
      "Deep Learning",
      "LLM",
      "vLLM",
      "PagedAttention",
      "CUDA",
      "Performance",
      "Open Source"
    ]
  }
]